


Access the VM via IP ----

vagrant ssh serverS
ssh vagrant@192.168.56.110

Vagrant nodes → vagrant status / vagrant global-status

Kubernetes nodes → kubectl get nodes



vagrant up serverS
vagrant up
vagrant ssh serverS
vagrant destroy -f
vagrant ssh serverSW
vagrant reload
vagrant validate
vagrant halt


# Get pod name
kubectl get pods

# Exec into pod
kubectl exec -it app1-xxx-yyy -- /bin/sh




sudo kubectl get nodes



kubectl run test-pod --image=nginx:alpine

kubectl get pods 
kubectl get pods -o wide
kubectl get pods --all-namespaces
kubectl get pods --watch

accss iside the contianer : ....
kubectl exec -it <pod_name> -- /bin/sh

kubectl logs <pod_name>
kubectl describe pod <pod_name>

 kubectl scale deployment <pod_name> --replicas=2


sudo cat /var/lib/rancher/k3s/server/token
K10b19f0eae80e361f57ec0bb4b4f859d9c797cdd50b07b03d2cc4c535d041d5985::server:3a7b064d5135c897160f60a17ca29aaf


# Check if K3s is running
sudo systemctl status k3s

# Check nodes
sudo kubectl get nodes



sudo kubectl describe pod test-nginx

sudo kubectl delete pod test-nginx
kubectl delete deployment <pod_name> // if the pod made by a deployment ...

sudo kubectl get pods

vagrant status






ps aux | grep -E 'vagrant'3
kill -9 5197 5198 520
vagrant destroy -f



kubectl run test-nginx --image=nginx
kubectl get nodes
kubectl get deployments
kubectl get services
kubectl get ingress
kubectl get pods 


kubectl version --client


kubectl apply -f test.yaml
kubectl get all
kubectl port-forward pod/app1-566f4b5989-c4bxk 8080:80
kubectl port-forward pod/<pod-name> 8080:80

kubectl run my-nginx --image=nginx:alpine --port=80
kubectl get pods
kubectl describe pod my-nginx
kubectl delete pod my-nginx


kubectl apply -f my-deployment.yaml
kubectl get deployments
kubectl scale deployment my-deployment --replicas=3
kubectl rollout status deployment my-deployment
kubectl delete deployment my-deployment


kubectl expose deployment my-deployment --type=NodePort --port=80
kubectl get svc
kubectl delete svc my-deployment


kubectl apply -f my-ingress.yaml
kubectl get ingress




kubectl get all          # see everything
kubectl get nodes        # see nodes
kubectl logs my-nginx    # view pod logs
kubectl exec -it my-nginx -- sh   # enter pod shell


kubectl get services

kubectl explain deployment
kubectl explain service
kubectl explain ingress



kubectl describe pod <pod_name>
kubectl exec -it <pod_name> -- sh

kubectl get endpoints app1-service
kubectl scale deployment app1-deployment --replicas=3



kubectl apply -f /vagrant/confs/ingress.yaml
kubectl get ingress
kubectl delete ingress apps-ingress


kubectl get deployments

kubectl cluster-info dump

============================================================================
Part3: 
============================================================================

remove docker ------------------------
sudo apt purge -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
sudo rm -rf /var/lib/docker /var/lib/containerd /etc/docker
sudo groupdel docker 2>/dev/null || true
sudo apt autoremove -y

==> docker --version

remove kubectl --------------------
sudo snap remove kubectl 2>/dev/null || true; sudo rm -f /usr/local/bin/kubectl /usr/bin/kubectl /snap/bin/kubectl; hash -r; command -v kubectl

==>  which kubectl - command -v kubectl - kubectl version --client

remove k3d -----------------

sudo k3d cluster list -o json | jq -r '.[].name' | xargs -r -n1 sudo k3d cluster delete; sudo rm -f /usr/local/bin/k3d

==> k3d version 






kubectl cluster-info
k3d cluster list

k3d cluster  create      Create a new cluster
k3d cluster  delete      Delete cluster(s).
k3d cluster  edit        [EXPERIMENTAL] Edit cluster(s).
k3d cluster  list        List cluster(s)
k3d cluster  start       Start existing k3d cluster(s)
k3d cluster  stop        Stop existing k3d cluster(s)
  






k3d kubeconfig merge cluster-test -d --overwrite

kubectl config current-context
kubectl config get-contexts

kubectl run test-nginx --image=nginx



kubectl create namespace test-namespace
kubectl get namespaces
kubectl config set-context --current --namespace=test-namespace
kubectl edit namespace test-namespace
kubectl get namespace test-namespace --show-labels
kubectl delete namespace test-namespace


kubectl get pods -n argocd
kubectl get deployment argocd-server -n argocd
kubectl config set-context --current --namespace=argocd
kubectl delete -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml


Argo CD admin password.
Username: admin
password : kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath="{.data.password}" | base64 --decode




ports --------------------
lsof -i

find : sudo lsof -i :8085
kill: sudo kill -9 <PID>


kill : sudo pkill -f "port-forward.*8085"
forward : kubectl port-forward svc/argocd-server -n argocd 8085:443

get pod name : kubectl get pods -n dev 
forwarding the prot : kubectl port-forward $POD_NAME -n dev 8888:8888








visite : 
http://localhost:8085
or (if you have a remote server)

ssh -L 8085:localhost:8085 user@your-vm-ip
curl -k https://localhost:8085



specifying a namespace ......................
Get Current namespace : kubectl config view --minify --output 'jsonpath={..namespace}'
SWITCH NAMESPACES : kubectl config set-context --current --namespace=dev

kubectl delete -f application.yaml
kubectl get nodes -n dev
kubectl get pods -n dev



git clone --recurse-submodules <repo-url>
git submodule update --init --recursive



